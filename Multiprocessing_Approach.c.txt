
// Compilation instructions for different process counts
// gcc -o Multiprocessing_Approach Multiprocessing_Approach.c
// ./Multiprocessing_Approach 2  # For 2 processes
// ./Multiprocessing_Approach 4  # For 4 processes
// ./Multiprocessing_Approach 6  # For 6 processes
// ./Multiprocessing_Approach 8  # For 8 processes

// Required header files for system calls, file operations, and process management
#include <stdio.h>      // Standard input/output operations
#include <stdlib.h>     // Memory allocation, random numbers, integer arithmetics
#include <string.h>     // String manipulation functions
#include <time.h>       // Time-related functions
#include <unistd.h>     // POSIX operating system API
#include <sys/wait.h>   // Process control, wait operations
#include <sys/stat.h>   // File status and information
#include <sys/shm.h>    // Shared memory operations
#include <fcntl.h>      // File control options
#include <sys/mman.h>

// Constants definition
#define MAX_WORD_LENGTH 100      // Maximum length of a single word
#define INITIAL_ARRAY_SIZE 1000000  // Initial size of dynamic arrays
#define PROGRESS_INTERVAL 60     // Time interval for progress updates (in seconds)

// Structure to store word and its frequency
typedef struct {
    char* word;         // Pointer to store the word string
    int frequency;      // Counter for word occurrences
} WordFreq;

// Structure for shared memory between processes
typedef struct {
    long total_words;    // Total number of words processed
    int unique_words;    // Number of unique words found
    time_t start_time;   // Start time of processing
} SharedData;

// Global pointer to shared memory
SharedData* shared_data;

// Function to print progress information
void print_progress(long total_words, int unique_words, time_t start_time) {
    time_t current_time = time(NULL);    // Get current time
    double elapsed = difftime(current_time, start_time);  // Calculate elapsed time
    printf("Progress: Processed %ld words, %d unique words found (%.2f minutes elapsed)\n", 
           total_words, unique_words, elapsed / 60.0);
    fflush(stdout);  // Force output buffer flush
}

// Function to swap two WordFreq elements (used in heap sort)
void swap(WordFreq* a, WordFreq* b) {
    WordFreq temp = *a;  // Create temporary storage
    *a = *b;            // Swap first element
    *b = temp;          // Swap second element
}

// Heapify function for heap sort
void heapify(WordFreq arr[], int n, int i) {
    int largest = i;        // Initialize largest as root
    int left = 2 * i + 1;   // Left child index
    int right = 2 * i + 2;  // Right child index

    // If left child is larger than root
    if (left < n && arr[left].frequency > arr[largest].frequency)
        largest = left;

    // If right child is larger than largest so far
    if (right < n && arr[right].frequency > arr[largest].frequency)
        largest = right;

    // If largest is not root
    if (largest != i) {
        swap(&arr[i], &arr[largest]);
        heapify(arr, n, largest);  // Recursively heapify affected sub-tree
    }
}

// Main heap sort function
void heap_sort(WordFreq arr[], int n) {
    // Build heap (rearrange array)
    for (int i = n / 2 - 1; i >= 0; i--)
        heapify(arr, n, i);

    // Extract elements from heap one by one
    for (int i = n - 1; i > 0; i--) {
        swap(&arr[0], &arr[i]);    // Move current root to end
        heapify(arr, i, 0);        // Call heapify on reduced heap
    }
}

// Function to find or add a word in the array
int find_or_add_word(WordFreq* words, int* size, const char* word) {
    // Search for existing word
    for (int i = 0; i < *size; i++) {
        if (strcmp(words[i].word, word) == 0) {
            words[i].frequency++;  // Increment frequency if found
            return i;
        }
    }

    // Add new word if not found
    words[*size].word = strdup(word);  // Create copy of word
    if (words[*size].word == NULL) {
        perror("Memory allocation failed for word");
        exit(1);
    }
    words[*size].frequency = 1;  // Initialize frequency
    (*size)++;                   // Increment array size
    return *size - 1;           // Return index of new word
}

// Function to get file size
long get_file_size(const char* filename) {
    struct stat st;
    if (stat(filename, &st) == 0)  // Get file statistics
        return st.st_size;         // Return file size
    return -1;                     // Return error code if failed
}

// Function to process a chunk of the file
WordFreq* process_file_chunk(const char* filename, long start_pos, long chunk_size, 
                           int process_id, int* local_unique_words) {
    // Open file for reading
    FILE* file = fopen(filename, "r");
    if (!file) {
        perror("Error opening file");
        exit(1);
    }

    // Set file position to start of chunk
    fseek(file, start_pos, SEEK_SET);

    // Allocate memory for words array
    WordFreq* words = malloc(INITIAL_ARRAY_SIZE * sizeof(WordFreq));
    if (!words) {
        perror("Memory allocation failed");
        fclose(file);
        exit(1);
    }

    // Initialize variables for processing
    char word[MAX_WORD_LENGTH];
    int array_size = INITIAL_ARRAY_SIZE;
    *local_unique_words = 0;
    long local_total_words = 0;
    long bytes_read = 0;
    time_t last_progress = time(NULL);

    // Process words in chunk
    while (bytes_read < chunk_size && fscanf(file, "%99s", word) == 1) {
        local_total_words++;
        bytes_read += strlen(word) + 1;

        // Resize array if needed
        if (*local_unique_words >= array_size) {
            array_size *= 2;
            WordFreq* temp = realloc(words, array_size * sizeof(WordFreq));
            if (!temp) {
                perror("Memory reallocation failed");
                for (int i = 0; i < *local_unique_words; i++) {
                    free(words[i].word);
                }
                free(words);
                fclose(file);
                exit(1);
            }
            words = temp;
        }

        // Process word
        find_or_add_word(words, local_unique_words, word);

        // Update shared statistics atomically
        __sync_fetch_and_add(&shared_data->total_words, 1);

        // Print progress if interval elapsed
        time_t current = time(NULL);
        if (difftime(current, last_progress) >= PROGRESS_INTERVAL) {
            printf("Process %d: Processed %ld words, %d unique words\n", 
                   process_id, local_total_words, *local_unique_words);
            last_progress = current;
        }
    }

    fclose(file);
    printf("Process %d completed: %ld words processed, %d unique words found\n",
           process_id, local_total_words, *local_unique_words);
    return words;
}

// Function to merge results from all processes
WordFreq* merge_results(WordFreq** process_results, int* process_unique_words, 
                       int num_processes, int* final_unique_words) {
    // Allocate memory for merged results
    WordFreq* merged = malloc(INITIAL_ARRAY_SIZE * sizeof(WordFreq));
    if (!merged) {
        perror("Memory allocation failed for merge");
        exit(1);
    }

    *final_unique_words = 0;
    int merged_size = INITIAL_ARRAY_SIZE;

    // Merge results from all processes
    for (int p = 0; p < num_processes; p++) {
        for (int i = 0; i < process_unique_words[p]; i++) {
            int found = 0;
            // Check if word already exists in merged results
            for (int j = 0; j < *final_unique_words; j++) {
                if (strcmp(process_results[p][i].word, merged[j].word) == 0) {
                    merged[j].frequency += process_results[p][i].frequency;
                    found = 1;
                    break;
                }
            }

            // Add new word if not found
            if (!found) {
                // Resize merged array if needed
                if (*final_unique_words >= merged_size) {
                    merged_size *= 2;
                    WordFreq* temp = realloc(merged, merged_size * sizeof(WordFreq));
                    if (!temp) {
                        perror("Memory reallocation failed during merge");
                        exit(1);
                    }
                    merged = temp;
                }
                // Add new word
                merged[*final_unique_words].word = strdup(process_results[p][i].word);
                merged[*final_unique_words].frequency = process_results[p][i].frequency;
                (*final_unique_words)++;
            }
        }
    }

    return merged;
}

// Main function
int main(int argc, char* argv[]) {
    // Check command line arguments
    if (argc != 2) {
        printf("Usage: %s <num_processes>\n", argv[0]);
        return 1;
    }

    // Validate number of processes
    int num_processes = atoi(argv[1]);
    if (num_processes <= 0 || num_processes > 8) {
        printf("Number of processes must be between 1 and 8\n");
        return 1;
    }

    // Create shared memory segment
    int shm_id = shmget(IPC_PRIVATE, sizeof(SharedData), IPC_CREAT | 0666);
    if (shm_id < 0) {
        perror("shmget failed");
        exit(1);
    }

    // Attach shared memory
    shared_data = (SharedData*)shmat(shm_id, NULL, 0);
    if (shared_data == (void*)-1) {
        perror("shmat failed");
        exit(1);
    }

    // Initialize shared data
    shared_data->total_words = 0;
    shared_data->unique_words = 0;
    shared_data->start_time = time(NULL);

    // Get file size and calculate chunk size
    long file_size = get_file_size("text8.txt");
    if (file_size == -1) {
        perror("Error getting file size");
        exit(1);
    }

    // Calculate chunk size for each process
    long chunk_size = file_size / num_processes;
    pid_t pids[num_processes];
    WordFreq* process_results[num_processes];
    int process_unique_words[num_processes];

    printf("Starting word frequency analysis with %d processes...\n", num_processes);
    time_t total_start = time(NULL);

    // Create child processes
    for (int i = 0; i < num_processes; i++) {
        pids[i] = fork();

        if (pids[i] < 0) {
            perror("Fork failed");
            exit(1);
        } else if (pids[i] == 0) {  // Child process
            // Calculate chunk boundaries
            long start_pos = i * chunk_size;
            long process_chunk_size = (i == num_processes - 1) ? 
                                    (file_size - start_pos) : chunk_size;

            // Process chunk
            int local_unique_words = 0;
            WordFreq* local_results = process_file_chunk("text8.txt", start_pos, 
                                                       process_chunk_size, i, 
                                                       &local_unique_words);

            // Save results to temporary file
            char filename[32];
            sprintf(filename, "temp_results_%d.bin", i);
            FILE* temp_file = fopen(filename, "wb");
            if (!temp_file) {
                perror("Error creating temporary file");
                exit(1);
            }

            // Write results to file
            fwrite(&local_unique_words, sizeof(int), 1, temp_file);
            for (int j = 0; j < local_unique_words; j++) {
                int word_len = strlen(local_results[j].word) + 1;
                fwrite(&word_len, sizeof(int), 1, temp_file);
                fwrite(local_results[j].word, 1, word_len, temp_file);
                fwrite(&local_results[j].frequency, sizeof(int), 1, temp_file);
            }

            fclose(temp_file);

            // Cleanup and exit
            for (int j = 0; j < local_unique_words; j++) {
                free(local_results[j].word);
            }
            free(local_results);
            exit(0);
        }
    }

    // Wait for all child processes and collect results
    for (int i = 0; i < num_processes; i++) {
        int status;
        waitpid(pids[i], &status, 0);  // Wait for child process

        // Read results from temporary file
        char filename[32];
        sprintf(filename, "temp_results_%d.bin", i);
        FILE* temp_file = fopen(filename, "rb");
        if (!temp_file) {
            perror("Error opening temporary file");
            exit(1);
        }

        // Read number of unique words
        fread(&process_unique_words[i], sizeof(int), 1, temp_file);

        // Allocate memory and read results
        process_results[i] = malloc(process_unique_words[i] * sizeof(WordFreq));
        for (int j = 0; j < process_unique_words[i]; j++) {
            int word_len;
            fread(&word_len, sizeof(int), 1, temp_file);
            process_results[i][j].word = malloc(word_len);
            fread(process_results[i][j].word, 1, word_len, temp_file);
            fread(&process_results[i][j].frequency, sizeof(int), 1, temp_file);
        }

        fclose(temp_file);
        remove(filename);  // Delete temporary file
    }

    // Merge results from all processes
    int final_unique_words;
    WordFreq* final_results = merge_results(process_results, process_unique_words, 
                                          num_processes, &final_unique_words);

    // Sort results
    printf("\nSorting words by frequency...\n");
    heap_sort(final_results, final_unique_words);

    // Print top 10 results
    printf("\nTop 10 most frequent words:\n");
    printf("%-20s %s\n", "Word", "Frequency");
    printf("----------------------------------------\n");
    for (int i = final_unique_words - 1; i >= final_unique_words - 10 && i >= 0; i--) {
        printf("%-20s %d\n", final_results[i].word, final_results[i].frequency);
    }

    time_t total_end = time(NULL);
    double total_time = difftime(total_end, total_start);
    printf("\nTotal execution time: %.2f seconds\n", total_time);

    for (int i = 0; i < num_processes; i++) {
        for (int j = 0; j < process_unique_words[i]; j++) {
            free(process_results[i][j].word);
        }
        free(process_results[i]);
    }
    for (int i = 0; i < final_unique_words; i++) {
        free(final_results[i].word);
    }
    free(final_results);

    shmdt(shared_data);
    shmctl(shm_id, IPC_RMID, NULL);

    return 0;
}