# Parallel Word Frequency Analysis

## Overview

This project implements and compares three different approaches for analyzing the frequency of words in a large text file: a **Naive (Sequential)** approach, a **Multiprocessing** approach using `fork()`, and a **Multithreading** approach using `pthread`. The goal is to demonstrate and measure the performance benefits of parallel processing for a CPU-bound task.

## Description

The program reads a text file (expected to be `text8.txt`), counts the occurrences of each unique word, and identifies the top 10 most frequent words. The core functionality is implemented in three distinct C files, each utilizing a different parallelization strategy (or none in the naive case). The parallel implementations divide the input file into chunks, process them concurrently, and then merge the results to produce the final word frequencies.

## Files

*   `Naive_Approach.c`: Implements the word frequency analysis sequentially in a single thread.
*   `Multiprocessing_Approach.c`: Implements the analysis using multiple child processes created with `fork()`. Results from each process are saved to temporary files and then merged by the parent.
*   `Multithreading_Approach.c`: Implements the analysis using multiple POSIX threads created with `pthread_create()`. Threads share memory and use mutexes for synchronization.
*   `text8.txt`: The large input text file used for word frequency analysis. (This file is required for the programs to run).
*   `Report.pdf`: A detailed report discussing the implementation, performance analysis (including speedup and efficiency calculations), comparison of the three approaches, and analysis using Amdahl's Law. (Based on the provided PDF content).

## Implemented Approaches

1.  **Naive (Sequential):**
    *   Single thread processes the entire file from start to end.
    *   Uses dynamic arrays (`malloc`, `realloc`) to store word frequencies.
    *   Sorts using Heap Sort.
    *   Simple to understand and debug, serves as a baseline for performance comparison.

2.  **Multiprocessing:**
    *   Parent process forks multiple child processes.
    *   Each child process handles a distinct chunk of the input file.
    *   Child processes find local word frequencies and save results to temporary files.
    *   The parent process waits for children to complete, reads results from temporary files, merges them, and performs the final sort and output.
    *   Leverages multiple CPU cores for true parallelism, avoiding limitations like Python's GIL (though GIL isn't relevant in C, it's a common point of comparison for process vs thread parallelism).

3.  **Multithreading:**
    *   Main thread creates multiple worker threads using `pthread_create()`.
    *   Each thread processes a distinct chunk of the input file.
    *   Threads share the main process's memory space.
    *   Synchronization is managed using a mutex (`pthread_mutex_t`) when updating shared counters (like total words).
    *   Results (local word frequency arrays) are generated by each thread and then merged by the main thread before final sorting and output.
    *   Generally lower overhead compared to processes, efficient for tasks involving shared data.

## Features

*   Reads a large text file (`text8.txt`).
*   Counts the frequency of unique words.
*   Finds and prints the top 10 most frequent words.
*   Implements the analysis using Sequential, Multiprocessing (`fork()`, temporary files), and Multithreading (`pthread`, shared memory, mutex) methods.
*   Measures and reports the execution time for each approach.
*   (Implicitly facilitates performance comparison across different thread/process counts as demonstrated in the report).

## Requirements

*   A C compiler (like GCC).
*   A Unix-like operating system (Linux, macOS, WSL) for `fork()`, `pthread`, and standard POSIX library support.
*   The `pthread` library (usually included with GCC, link with `-pthread`).
*   Standard C libraries (`stdio.h`, `stdlib.h`, `string.h`, `time.h`, `unistd.h`).
*   For Multiprocessing: `sys/wait.h`, `sys/stat.h`, `fcntl.h`, `sys/shm.h`, `sys/mman.h`.
*   The input file `text8.txt` in the same directory as the compiled executables.

## How to Build and Run

Ensure you have a C compiler (like GCC) installed and are in a Unix-like environment.

1.  **Clone or Download:** Get the project files onto your machine.
2.  **Obtain `text8.txt`:** Download the `text8.txt` dataset (it's a common benchmark file, easily found online). Place it in the project directory.
3.  **Navigate to Project Directory:** Open a terminal and go to the directory containing the source files.

4.  **Compile:**
    *   **Naive:**
        ```bash
        gcc -o Naive_Approach Naive_Approach.c -Wall
        ```
    *   **Multiprocessing:**
        ```bash
        gcc -o Multiprocessing_Approach Multiprocessing_Approach.c
        ```
    *   **Multithreading:**
        ```bash
        gcc -o Multithreading_Approach Multithreading_Approach.c -pthread
        ```

5.  **Run:**
    *   **Naive (Sequential):**
        ```bash
        ./Naive_Approach
        ```
    *   **Multiprocessing:** (Specify the number of processes, e.g., 2, 4, 6, 8)
        ```bash
        ./Multiprocessing_Approach <num_processes>
        # Example for 4 processes:
        # ./Multiprocessing_Approach 4
        ```
    *   **Multithreading:** (Specify the number of threads, e.g., 2, 4, 6, 8)
        ```bash
        ./Multithreading_Approach <num_threads>
        # Example for 8 threads:
        # ./Multithreading_Approach 8
        ```

## Performance Analysis (See Report.pdf)

The core value of this project lies in comparing the execution times of these three approaches with varying degrees of parallelism. Run the multiprocessing and multithreading versions with different arguments (2, 4, 6, 8 processes/threads) and compare their execution times to the naive approach. The accompanying `Report.pdf` provides a detailed analysis of these results, including speedup, efficiency, and discussion based on Amdahl's Law and the specific hardware characteristics.

## Author

*   Name: Amir Al-Rashayda
